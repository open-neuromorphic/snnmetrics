{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sinabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sinabs.activation as sa\n",
    "import sinabs.layers as sl\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "hidden_dim1 = 256\n",
    "hidden_dim2 = 128\n",
    "\n",
    "\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(28, hidden_dim1)\n",
    "        self.spike1 = sl.LIF(tau_mem=10.0, spike_fn=sa.SingleSpike)\n",
    "        self.linear2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.spike2 = sl.LIF(tau_mem=10.0, spike_fn=sa.SingleSpike)\n",
    "        self.linear3 = nn.Linear(hidden_dim2, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out1 = self.spike1(self.linear1(x))\n",
    "        out2 = self.spike2(self.linear2(out1))\n",
    "        out3 = self.linear3(out2)\n",
    "        return out3, (out1, out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = datasets.MNIST(\n",
    "    root=\"../data/\", train=True, transform=transforms.ToTensor(), download=True\n",
    ");\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, drop_last=True, num_workers=4\n",
    ");\n",
    "\n",
    "testset = datasets.MNIST(\n",
    "    root=\"../data/\", train=False, transform=transforms.ToTensor(), download=True\n",
    ");\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, drop_last=True, num_workers=4\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sinabs\n",
    "import torchmetrics\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "snn = SNN().to(device)\n",
    "optim = torch.optim.Adam(snn.parameters())\n",
    "criterion = torch.nn.functional.cross_entropy\n",
    "accuracy = torchmetrics.Accuracy(\"multiclass\", num_classes=10).to(device)\n",
    "\n",
    "for epoch in range(3):\n",
    "    losses = []\n",
    "    accuracy.reset()\n",
    "    for x, y in tqdm(trainloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        sinabs.reset_states(snn)\n",
    "        optim.zero_grad()\n",
    "        # we squeeze the image channel dimension\n",
    "        output, (out1, out2) = snn(x.squeeze())\n",
    "        y_hat = output.sum(1)  # we sum over time\n",
    "        loss = criterion(y_hat, y)\n",
    "        losses.append(loss)\n",
    "        batch_stats = accuracy(y_hat, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    print(\n",
    "        f\"Epoch {epoch}: loss {torch.stack(losses).mean()} training accuracy {accuracy.compute()}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snnmetrics as sm\n",
    "\n",
    "synops1 = sm.SynOps(fanout=hidden_dim1)\n",
    "synops2 = sm.SynOps(fanout=hidden_dim2)\n",
    "\n",
    "snn.eval()\n",
    "losses = []\n",
    "accuracy.reset()\n",
    "for x, y in tqdm(testloader):\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    sinabs.reset_states(snn)\n",
    "    output, (out1, out2) = snn(x.squeeze())  # we squeeze the single channel dimension\n",
    "    y_hat = output.sum(1)  # we sum over time\n",
    "    batch_syn1 = synops1(out1.sum(1))\n",
    "    batch_syn2 = synops2(out2.sum(1))\n",
    "    batch_acc = accuracy(y_hat, y)\n",
    "print(\n",
    "    f\"Test accuracy {accuracy.compute()}, synops layer 1 {synops1.compute()['synops']}, layer 2 {synops2.compute()['synops']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synops1.compute()[\"synops_per_neuron\"] / hidden_dim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1.sum(1).mean(0) * hidden_dim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_syn1[\"synops_per_neuron\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
